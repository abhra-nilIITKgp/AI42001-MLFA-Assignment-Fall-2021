{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Lab_03_11_2021_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH8U1hYMRB-Z"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnoO3_J_RB-j"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWTRKFkRRB-k"
      },
      "source": [
        "# 1. How to implement layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AhIUbXdRB-k"
      },
      "source": [
        "#~ 1.1 Convolution Layer ~#\n",
        "#layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "\n",
        "#~ 1.2 Maxpool Layer ~#\n",
        "#layers.MaxPooling2D(),\n",
        "\n",
        "#~ 1.3 FC (Fully Connected Layer) ~#\n",
        "#layers.Flatten(),\n",
        "#layers.Dense(64, activation='relu'),\n",
        "#layers.Dense(10),\n",
        "\n",
        "#~ 1.4 with the above basics, please show how one can build a new CNN model from scratch ~#\n",
        "def my_model():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            keras.layers.InputLayer((32, 32, 3)),\n",
        "            layers.Conv2D(32, 3, padding='valid', activation='relu'), \n",
        "            #reference : https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "            layers.MaxPooling2D(),  # by default pool_size=(2, 2)\n",
        "            layers.Conv2D(64, 3, activation='relu'),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(128, 3, activation='relu'),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(10),#output \n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = my_model()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33V33bfSRB-l"
      },
      "source": [
        "# 2. Quick intro to backprop on CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCl166bjRB-m"
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3wovXv0yBYA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeYFeQqYRB-n"
      },
      "source": [
        "# 3. CNN over the grey image (1-channel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UEqI56_RB-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb92bf5-7bac-4e4b-da74-4679622ab93d"
      },
      "source": [
        "#~ NOTE: MNIST is a grayscale (1-channel) Dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "x_train = tf.expand_dims(x_train, axis=3)\n",
        "#y_train = tf.expand_dims(y_train, axis=1)\n",
        "x_test = tf.expand_dims(x_test, axis=3)\n",
        "#y_test = tf.expand_dims(y_test, axis=1)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "def model_cnn_grayscale():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            #~ NOTE: images are 28x28, last number (1) denotes number of channels\n",
        "            keras.layers.InputLayer((28, 28, 1)),\n",
        "            layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(64, 3, activation='relu'),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(128, 3, activation='relu'),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(10),\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = model_cnn_grayscale()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "Epoch 1/5\n",
            "938/938 - 54s - loss: 0.3136 - accuracy: 0.9280\n",
            "Epoch 2/5\n",
            "938/938 - 54s - loss: 0.0743 - accuracy: 0.9779\n",
            "Epoch 3/5\n",
            "938/938 - 54s - loss: 0.0459 - accuracy: 0.9857\n",
            "Epoch 4/5\n",
            "938/938 - 54s - loss: 0.0328 - accuracy: 0.9899\n",
            "Epoch 5/5\n",
            "938/938 - 54s - loss: 0.0277 - accuracy: 0.9907\n",
            "157/157 - 3s - loss: 0.0601 - accuracy: 0.9810\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06010286882519722, 0.9810000061988831]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYjdaTqtRB-p"
      },
      "source": [
        "# 4. CNN over RGB image (multi-channel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf1_F7e3RB-q",
        "outputId": "c35f5dab-a219-4051-bcc3-140fb2829231"
      },
      "source": [
        "#~ NOTE: CIFAR-10 is a RGB color (3-channel) Dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "def model_cnn_color():\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            #~ NOTE: images are 32x32, last number (3) denotes number of channels\n",
        "            keras.layers.InputLayer((32, 32, 3)),\n",
        "            layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(64, 3, activation='relu'),\n",
        "            layers.MaxPooling2D(),\n",
        "            layers.Conv2D(128, 3, activation='relu'),\n",
        "            layers.Flatten(),\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dense(10),\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = model_cnn_color()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "Epoch 1/5\n",
            "782/782 - 19s - loss: 2.4319 - accuracy: 0.0986\n",
            "Epoch 2/5\n",
            "782/782 - 19s - loss: 2.2956 - accuracy: 0.1023\n",
            "Epoch 3/5\n",
            "782/782 - 19s - loss: 1.8064 - accuracy: 0.3210\n",
            "Epoch 4/5\n",
            "782/782 - 19s - loss: 1.3717 - accuracy: 0.5073\n",
            "Epoch 5/5\n",
            "782/782 - 19s - loss: 1.1693 - accuracy: 0.5834\n",
            "157/157 - 1s - loss: 1.1491 - accuracy: 0.5950\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.1490956544876099, 0.5950000286102295]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v9hdEV9RB-s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}