{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.2929384   0.8884928   0.2542704 ]\n",
      " [-1.1739132   0.6591436   0.21706408]\n",
      " [-1.798928    1.2846293  -0.3608256 ]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor([[0.97719693 0.7548045  0.28464484]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int32)\n",
      "tf.Tensor([1 3 5 7 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor([1. 3. 5. 7. 9.], shape=(5,), dtype=float64)\n",
      "tf.Tensor(32, shape=(), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6 7], shape=(8,), dtype=int32)\n",
      "tf.Tensor([2 3 4 5 6 7], shape=(6,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([0 2 4 6], shape=(4,), dtype=int32)\n",
      "tf.Tensor([7 6 5 4 3 2 1 0], shape=(8,), dtype=int32)\n",
      "tf.Tensor([0 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 3 6]\n",
      " [1 4 7]\n",
      " [2 5 8]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# initialize tensors\n",
    "\n",
    "x_01 = tf.constant(4)\n",
    "print(x_01)\n",
    "\n",
    "x_02 = tf.constant(4.0)\n",
    "print(x_02)\n",
    "\n",
    "x_03 = tf.constant(4, shape=(1, 1), dtype=tf.float32)\n",
    "print(x_03)\n",
    "\n",
    "x_04 = tf.constant([[1, 2, 3], [4, 5, 6]])  # can also use shape, dtype etc.\n",
    "print(x_04)\n",
    "\n",
    "x_05 = tf.ones((3, 3))\n",
    "print(x_05)\n",
    "\n",
    "x_06 = tf.zeros((2, 3))\n",
    "print(x_06)\n",
    "\n",
    "x_07 = tf.eye(3)\n",
    "print(x_07)\n",
    "\n",
    "x_08 = tf.random.normal((3, 3), mean=0, stddev=1)\n",
    "print(x_08)\n",
    "\n",
    "x_09 = tf.random.uniform((1, 3), minval=0, maxval=1)\n",
    "print(x_09)\n",
    "\n",
    "x_10 = tf.range(9)\n",
    "print(x_10)\n",
    "\n",
    "x_11 = tf.range(start=1, limit=10, delta=2)\n",
    "print(x_11)\n",
    "\n",
    "# converting dtypes\n",
    "\n",
    "x_12 = tf.cast(tf.range(start=1, limit=10, delta=2), dtype=tf.float64)  # tf.int, tf.bool etc.\n",
    "print(x_12)\n",
    "\n",
    "# mathematical operations\n",
    "\n",
    "x = tf.constant([1, 2, 3])\n",
    "y = tf.constant([4, 5, 6])\n",
    "\n",
    "z_add = x + y  # z_add = tf.add(x, y)\n",
    "z_sub = x - y  # z_sub = tf.subtract(x, y)\n",
    "z_mul = x * y  # z_mul = tf.multiply(x, y)\n",
    "z_div = x / y  # z_div = tf.divide(x, y)\n",
    "\n",
    "z_exp = x ** 5\n",
    "\n",
    "z_dot = tf.tensordot(x, y, axes=1)  # dot product\n",
    "print(z_dot)\n",
    "\n",
    "x_2 = tf.random.normal((2, 3))\n",
    "y_2 = tf.random.normal((3, 4))\n",
    "z_matrix_mul = x_2 @ y_2  # tf.matmul(x, y)  # matrix multiplication\n",
    "\n",
    "# indexing\n",
    "\n",
    "x_3 = tf.range(8)\n",
    "print(x_3[:])  # same as print(x)\n",
    "print(x_3[2:])\n",
    "print(x_3[:5])\n",
    "print(x_3[4:7])\n",
    "\n",
    "print(x_3[::2])  # stepsize is 2\n",
    "print(x_3[::-1])  # reverse order\n",
    "\n",
    "indices = tf.constant([0, 3])  # indices to take specifically\n",
    "x_ind = tf.gather(x_3, indices)  # taking specific indices\n",
    "print(x_ind)\n",
    "\n",
    "x_4 = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "print(x_4[0, :])\n",
    "print(x_4[0:2, :])\n",
    "\n",
    "# reshaping\n",
    "\n",
    "x_5 = tf.range(9)\n",
    "\n",
    "x_reshape = tf.reshape(x_5, (3, 3))\n",
    "print(x_reshape)\n",
    "\n",
    "x_transpose = tf.transpose(x_reshape, perm=[1, 0])\n",
    "print(x_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training using Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_layer (Dense)          (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "second_layer (Dense)         (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "third_layer (Dense)          (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1875/1875 - 4s - loss: 0.1850 - accuracy: 0.9438\n",
      "Epoch 2/5\n",
      "1875/1875 - 4s - loss: 0.0798 - accuracy: 0.9747\n",
      "Epoch 3/5\n",
      "1875/1875 - 4s - loss: 0.0557 - accuracy: 0.9819\n",
      "Epoch 4/5\n",
      "1875/1875 - 4s - loss: 0.0397 - accuracy: 0.9869\n",
      "Epoch 5/5\n",
      "1875/1875 - 4s - loss: 0.0340 - accuracy: 0.9891\n",
      "313/313 - 0s - loss: 0.0850 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08496368676424026, 0.977400004863739]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "def my_model_fully_connected():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((784)),  # NOTE: not necessary, only written to print model.summary before fitting the model\n",
    "            layers.Dense(512, activation='relu', name='first_layer'),\n",
    "            layers.Dense(256, activation='relu', name='second_layer'),\n",
    "            layers.Dense(10, activation='softmax', name='third_layer'),\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = my_model_fully_connected()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),  # NOTE: default is from_logits=False\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)  # verbose=0 shows nothing, verbose=1 shows progress bar\n",
    "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'third_layer/kernel:0' shape=(256, 10) dtype=float32, numpy=\n",
      "array([[ 0.06439722,  0.20898345, -0.17276403, ..., -0.01441891,\n",
      "        -0.14783616, -0.1978984 ],\n",
      "       [ 0.05082258, -0.1767844 , -0.02470991, ..., -0.28280863,\n",
      "        -0.22264628, -0.05214815],\n",
      "       [-0.30604258,  0.3695053 , -0.25231773, ..., -0.05409916,\n",
      "        -0.06300288,  0.02404477],\n",
      "       ...,\n",
      "       [-0.02331541,  0.0987982 , -0.10431795, ..., -0.14169882,\n",
      "         0.14132002, -0.04418321],\n",
      "       [ 0.05873941, -0.09746395,  0.09404477, ..., -0.26448524,\n",
      "         0.02616014,  0.087489  ],\n",
      "       [ 0.0884406 ,  0.04134963, -0.04357363, ..., -0.15174198,\n",
      "        -0.12054659,  0.08059086]], dtype=float32)>, <tf.Variable 'third_layer/bias:0' shape=(10,) dtype=float32, numpy=\n",
      "array([-0.00415965, -0.13461424, -0.00903633, -0.0716994 , -0.00954073,\n",
      "       -0.01700989, -0.06083748, -0.10527664,  0.24681701,  0.05397088],\n",
      "      dtype=float32)>]\n",
      "[-0.00415965 -0.13461424 -0.00903633 -0.0716994  -0.00954073 -0.01700989\n",
      " -0.06083748 -0.10527664  0.24681701  0.05397088]\n",
      "<tf.Variable 'third_layer/kernel:0' shape=(256, 10) dtype=float32, numpy=\n",
      "array([[ 0.06439722,  0.20898345, -0.17276403, ..., -0.01441891,\n",
      "        -0.14783616, -0.1978984 ],\n",
      "       [ 0.05082258, -0.1767844 , -0.02470991, ..., -0.28280863,\n",
      "        -0.22264628, -0.05214815],\n",
      "       [-0.30604258,  0.3695053 , -0.25231773, ..., -0.05409916,\n",
      "        -0.06300288,  0.02404477],\n",
      "       ...,\n",
      "       [-0.02331541,  0.0987982 , -0.10431795, ..., -0.14169882,\n",
      "         0.14132002, -0.04418321],\n",
      "       [ 0.05873941, -0.09746395,  0.09404477, ..., -0.26448524,\n",
      "         0.02616014,  0.087489  ],\n",
      "       [ 0.0884406 ,  0.04134963, -0.04357363, ..., -0.15174198,\n",
      "        -0.12054659,  0.08059086]], dtype=float32)>\n",
      "<tf.Variable 'third_layer/bias:0' shape=(10,) dtype=float32, numpy=\n",
      "array([-0.00415965, -0.13461424, -0.00903633, -0.0716994 , -0.00954073,\n",
      "       -0.01700989, -0.06083748, -0.10527664,  0.24681701,  0.05397088],\n",
      "      dtype=float32)>\n",
      "[-0.00415965 -0.13461424 -0.00903633 -0.0716994  -0.00954073 -0.01700989\n",
      " -0.06083748 -0.10527664  0.24681701  0.05397088]\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[2].weights)\n",
    "print(model.layers[2].bias.numpy())\n",
    "\n",
    "print(model.get_layer('third_layer').weights[0])\n",
    "print(model.get_layer('third_layer').weights[1])\n",
    "print(model.get_layer('third_layer').bias.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "782/782 - 19s - loss: 1.6649 - accuracy: 0.3907\n",
      "Epoch 2/5\n",
      "782/782 - 18s - loss: 1.3331 - accuracy: 0.5249\n",
      "Epoch 3/5\n",
      "782/782 - 19s - loss: 1.1935 - accuracy: 0.5806\n",
      "Epoch 4/5\n",
      "782/782 - 19s - loss: 1.1014 - accuracy: 0.6134\n",
      "Epoch 5/5\n",
      "782/782 - 19s - loss: 1.0253 - accuracy: 0.6440\n",
      "157/157 - 1s - loss: 1.0140 - accuracy: 0.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.014009952545166, 0.6467000246047974]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "def my_model_cnn():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((32, 32, 3)),\n",
    "            layers.Conv2D(32, 3, padding='valid', activation='relu'),  # Kernel size can also be written as (3, 3)  # padding can be 'same', 'valid' etc.\n",
    "            layers.MaxPooling2D(),  # by default pool_size=(2, 2)\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, activation='relu'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = my_model_cnn()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,930\n",
      "Trainable params: 225,482\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "782/782 - 29s - loss: 1.3422 - accuracy: 0.5192\n",
      "Epoch 2/5\n",
      "782/782 - 29s - loss: 0.9743 - accuracy: 0.6594\n",
      "Epoch 3/5\n",
      "782/782 - 28s - loss: 0.8201 - accuracy: 0.7142\n",
      "Epoch 4/5\n",
      "782/782 - 29s - loss: 0.7112 - accuracy: 0.7538\n",
      "Epoch 5/5\n",
      "782/782 - 29s - loss: 0.6335 - accuracy: 0.7792\n",
      "157/157 - 2s - loss: 0.9282 - accuracy: 0.6890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9281631112098694, 0.6890000104904175]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_model_cnn_batchnorm():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((32, 32, 3)),\n",
    "            layers.Conv2D(32, 3, padding='valid'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = my_model_cnn_batchnorm()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization (L2 and Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,930\n",
      "Trainable params: 225,482\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "782/782 - 29s - loss: 3.2802 - accuracy: 0.4006\n",
      "Epoch 2/25\n",
      "782/782 - 27s - loss: 1.9669 - accuracy: 0.5653\n",
      "Epoch 3/25\n",
      "782/782 - 28s - loss: 1.5293 - accuracy: 0.6219\n",
      "Epoch 4/25\n",
      "782/782 - 27s - loss: 1.3484 - accuracy: 0.6508\n",
      "Epoch 5/25\n",
      "782/782 - 28s - loss: 1.2520 - accuracy: 0.6703\n",
      "Epoch 6/25\n",
      "782/782 - 27s - loss: 1.1876 - accuracy: 0.6862\n",
      "Epoch 7/25\n",
      "782/782 - 28s - loss: 1.1471 - accuracy: 0.6990\n",
      "Epoch 8/25\n",
      "782/782 - 27s - loss: 1.1115 - accuracy: 0.7086\n",
      "Epoch 9/25\n",
      "782/782 - 28s - loss: 1.0872 - accuracy: 0.7190\n",
      "Epoch 10/25\n",
      "782/782 - 29s - loss: 1.0648 - accuracy: 0.7269\n",
      "Epoch 11/25\n",
      "782/782 - 28s - loss: 1.0497 - accuracy: 0.7314\n",
      "Epoch 12/25\n",
      "782/782 - 31s - loss: 1.0333 - accuracy: 0.7374\n",
      "Epoch 13/25\n",
      "782/782 - 31s - loss: 1.0229 - accuracy: 0.7405\n",
      "Epoch 14/25\n",
      "782/782 - 32s - loss: 1.0088 - accuracy: 0.7446\n",
      "Epoch 15/25\n",
      "782/782 - 33s - loss: 0.9940 - accuracy: 0.7518\n",
      "Epoch 16/25\n",
      "782/782 - 29s - loss: 0.9796 - accuracy: 0.7565\n",
      "Epoch 17/25\n",
      "782/782 - 29s - loss: 0.9761 - accuracy: 0.7600\n",
      "Epoch 18/25\n",
      "782/782 - 29s - loss: 0.9578 - accuracy: 0.7661\n",
      "Epoch 19/25\n",
      "782/782 - 29s - loss: 0.9531 - accuracy: 0.7684\n",
      "Epoch 20/25\n",
      "782/782 - 29s - loss: 0.9459 - accuracy: 0.7737\n",
      "Epoch 21/25\n",
      "782/782 - 30s - loss: 0.9378 - accuracy: 0.7766\n",
      "Epoch 22/25\n",
      "782/782 - 29s - loss: 0.9310 - accuracy: 0.7769\n",
      "Epoch 23/25\n",
      "782/782 - 30s - loss: 0.9263 - accuracy: 0.7797\n",
      "Epoch 24/25\n",
      "782/782 - 29s - loss: 0.9107 - accuracy: 0.7881\n",
      "Epoch 25/25\n",
      "782/782 - 30s - loss: 0.9172 - accuracy: 0.7860\n",
      "157/157 - 2s - loss: 1.0330 - accuracy: 0.7416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.032969355583191, 0.741599977016449]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def my_model_cnn_batchnorm_reg():\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((32, 32, 3)),\n",
    "            layers.Conv2D(32, 3, padding='valid', kernel_regularizer=regularizers.l2(0.01)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(0.01)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(128, 3, kernel_regularizer=regularizers.l2(0.01)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = my_model_cnn_batchnorm_reg()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=25, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
