{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Ynb7JJ-HUnzc"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "F3DZPentRed_"
   },
   "outputs": [],
   "source": [
    "# Function to generate a list of random numbers (not necessarily unique)\n",
    "\n",
    "def random_generator(seed = 0, low = 0, high = None, size = None):\n",
    "    s = seed\n",
    "    a = 11\n",
    "    b = 13\n",
    "\n",
    "    if high is None:\n",
    "        return (\"Error. Upper Limit not found\")\n",
    "    if size is None:\n",
    "        return (\"Error. Size not found\")\n",
    "    if size == 1:\n",
    "        return ((a*s+b)%high)\n",
    "    random_list = []\n",
    "    for i in range(size):\n",
    "        random_list.append((a*s+b)%high)\n",
    "        s = (a*s+b)\n",
    "    return random_list\n",
    "\n",
    "# Function to generate a list of random numbers (all unique)\n",
    "\n",
    "def unique_random_generator(seed = 0, low = 0, high = None, size = None):\n",
    "    s = seed\n",
    "    a = 3\n",
    "    b = 1\n",
    "\n",
    "    if high is None:\n",
    "        return (\"Error. Upper Limit not found\")\n",
    "    if size is None:\n",
    "        return (\"Error. Size not found\")\n",
    "    if size == 1:\n",
    "        return ((a*s+b)%high)\n",
    "    random_list = []\n",
    "    i = 0\n",
    "    while i < size:\n",
    "        z = (a*s+b)%high\n",
    "        if z in random_list:\n",
    "              b += 1\n",
    "              s = (a*s + b)%high\n",
    "              continue\n",
    "        random_list.append(z)\n",
    "        i += 1\n",
    "        s = ((a*s+b))%high+1\n",
    "    return random_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "T5rfJMVxWDqv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION DATASET : \n",
      "      feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0     0.00632      18.0      2.31       0.0     0.538     6.575      65.2   \n",
      "1     0.02731       0.0      7.07       0.0     0.469     6.421      78.9   \n",
      "2     0.02729       0.0      7.07       0.0     0.469     7.185      61.1   \n",
      "3     0.03237       0.0      2.18       0.0     0.458     6.998      45.8   \n",
      "4     0.06905       0.0      2.18       0.0     0.458     7.147      54.2   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "501   0.06263       0.0     11.93       0.0     0.573     6.593      69.1   \n",
      "502   0.04527       0.0     11.93       0.0     0.573     6.120      76.7   \n",
      "503   0.06076       0.0     11.93       0.0     0.573     6.976      91.0   \n",
      "504   0.10959       0.0     11.93       0.0     0.573     6.794      89.3   \n",
      "505   0.04741       0.0     11.93       0.0     0.573     6.030      80.8   \n",
      "\n",
      "     feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
      "0      4.0900       1.0      296.0       15.3     396.90       4.98   \n",
      "1      4.9671       2.0      242.0       17.8     396.90       9.14   \n",
      "2      4.9671       2.0      242.0       17.8     392.83       4.03   \n",
      "3      6.0622       3.0      222.0       18.7     394.63       2.94   \n",
      "4      6.0622       3.0      222.0       18.7     396.90       5.33   \n",
      "..        ...       ...        ...        ...        ...        ...   \n",
      "501    2.4786       1.0      273.0       21.0     391.99       9.67   \n",
      "502    2.2875       1.0      273.0       21.0     396.90       9.08   \n",
      "503    2.1675       1.0      273.0       21.0     396.90       5.64   \n",
      "504    2.3889       1.0      273.0       21.0     393.45       6.48   \n",
      "505    2.5050       1.0      273.0       21.0     396.90       7.88   \n",
      "\n",
      "     price(target)  \n",
      "0             24.0  \n",
      "1             21.6  \n",
      "2             34.7  \n",
      "3             33.4  \n",
      "4             36.2  \n",
      "..             ...  \n",
      "501           22.4  \n",
      "502           20.6  \n",
      "503           23.9  \n",
      "504           22.0  \n",
      "505           11.9  \n",
      "\n",
      "[506 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# reg_dataset -> Regression Dataset : Boston Dataset with Housing price as the target and 13 Features related to the houses.\n",
    "\n",
    "def load_dataset():\n",
    "    reg_x, reg_y = load_boston(return_X_y = True)\n",
    "    reg_data = np.concatenate((reg_x, np.array(reg_y).reshape(-1, 1)), axis = 1)\n",
    "    cols = [\"feature\"+str(i) for i in range(1, 14)]\n",
    "    cols = cols + [\"price(target)\"]\n",
    "    reg_dataset = pd.DataFrame(data = reg_data, columns = cols)\n",
    "\n",
    "    return reg_dataset\n",
    "\n",
    "reg_dataset = load_dataset()\n",
    "print(\"REGRESSION DATASET : \\n\", reg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "SGr0ZENNWDsr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
      "0     0.00632      18.0      2.31       0.0     0.538     6.575      65.2   \n",
      "1     0.02731       0.0      7.07       0.0     0.469     6.421      78.9   \n",
      "2     0.02729       0.0      7.07       0.0     0.469     7.185      61.1   \n",
      "3     0.03237       0.0      2.18       0.0     0.458     6.998      45.8   \n",
      "4     0.06905       0.0      2.18       0.0     0.458     7.147      54.2   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "501   0.06263       0.0     11.93       0.0     0.573     6.593      69.1   \n",
      "502   0.04527       0.0     11.93       0.0     0.573     6.120      76.7   \n",
      "503   0.06076       0.0     11.93       0.0     0.573     6.976      91.0   \n",
      "504   0.10959       0.0     11.93       0.0     0.573     6.794      89.3   \n",
      "505   0.04741       0.0     11.93       0.0     0.573     6.030      80.8   \n",
      "\n",
      "     feature8  feature9  feature10  feature11  feature12  feature13  \n",
      "0      4.0900       1.0      296.0       15.3     396.90       4.98  \n",
      "1      4.9671       2.0      242.0       17.8     396.90       9.14  \n",
      "2      4.9671       2.0      242.0       17.8     392.83       4.03  \n",
      "3      6.0622       3.0      222.0       18.7     394.63       2.94  \n",
      "4      6.0622       3.0      222.0       18.7     396.90       5.33  \n",
      "..        ...       ...        ...        ...        ...        ...  \n",
      "501    2.4786       1.0      273.0       21.0     391.99       9.67  \n",
      "502    2.2875       1.0      273.0       21.0     396.90       9.08  \n",
      "503    2.1675       1.0      273.0       21.0     396.90       5.64  \n",
      "504    2.3889       1.0      273.0       21.0     393.45       6.48  \n",
      "505    2.5050       1.0      273.0       21.0     396.90       7.88  \n",
      "\n",
      "[506 rows x 13 columns]\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into training and testing\n",
    "\n",
    "cols = [\"feature\"+str(i) for i in range(1, 14)]\n",
    "cols = cols + [\"price(target)\"]\n",
    "\n",
    "X = reg_dataset[cols[:-1]]\n",
    "Y = reg_dataset[cols[-1]]\n",
    "\n",
    "print(X)\n",
    "print(Y.values)\n",
    "\n",
    "TrainX = np.asarray(X)\n",
    "TrainY = np.asarray(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(TrainX, TrainY, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH_qoLuNztqM"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "HKIS746vWDxJ"
   },
   "outputs": [],
   "source": [
    "dt1 = DecisionTreeRegressor(max_depth = 3, random_state = 10)\n",
    "row_index = random_generator(0, 0, 404, 404)\n",
    "col_index = unique_random_generator(0, 0, 13, 4)\n",
    "\n",
    "dt2 = DecisionTreeRegressor(max_depth = 3, random_state = 10)\n",
    "row_index = random_generator(2, 0, 404, 404)\n",
    "col_index = unique_random_generator(2, 0, 13, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "8AXdMYFLMv1b"
   },
   "outputs": [],
   "source": [
    "# fifty different Decision Trees\n",
    "\n",
    "subset_seed = random_generator(10, 0, 400, 50)\n",
    "for i in range(50):\n",
    "    dt_temp = DecisionTreeRegressor(max_depth = 3, random_state = 3)\n",
    "    row_index = random_generator(subset_seed[i], 0, 404, 404)\n",
    "    col_index = unique_random_generator(subset_seed[i], 0, 13, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "LAbomDO2iMJW"
   },
   "outputs": [],
   "source": [
    "# varying number of decision trees from 4 to 148\n",
    "\n",
    "for n in range (4, 150, 2):\n",
    "    subset_seed = random_generator(15, 0, 400, n)\n",
    "    for i in range(n):\n",
    "        dt_temp = DecisionTreeRegressor(max_depth = 3, random_state = 3)\n",
    "        row_index = random_generator(subset_seed[i], 0, 404, 404)\n",
    "        col_index = unique_random_generator(subset_seed[i], 0, 13, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "IdgzqnfeTNnW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=3, max_features=4, max_samples=404,\n",
       "                      n_estimators=50, random_state=10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn Random Forest Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 50, max_depth = 3, max_features = 4, max_samples = 404, random_state = 10)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvsJ-G59C16X"
   },
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UG_5BS3HOyh"
   },
   "source": [
    "\n",
    "\n",
    "Unlike Random Forest, the trees are built sequentially.\n",
    "\n",
    "**Sample weights**: Weight given to each training sample.\n",
    "\n",
    "**Learning Rate**: A controlling rate for updating sample weights.\n",
    "\n",
    "**beta**: $\\frac{total error}{1 - total error}$\n",
    "\n",
    "**alpha**: $0.5 * learning\\_rate * log_e(\\frac{1}{beta})$\n",
    "\n",
    "You want to increase the sample weights of the predictions that have a large error.\n",
    "$sample\\_weight_{(n+1)th} = sample\\_weight_{nth}*beta^{(1 - error)* learning_rate}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aVePywOKo4m"
   },
   "outputs": [],
   "source": [
    "n = 80\n",
    "learning_rate = 0.01\n",
    "decision_trees = [None]*n\n",
    "alphas = [None]*n\n",
    "\n",
    "dt_temp = DecisionTreeRegressor(max_depth = 3, random_state = 10)\n",
    "\n",
    "#Create your training data and training labels\n",
    "#Create your testing data and testing labels\n",
    "#Initialise an array for sample weights. The weights should be normalized i.e all the weights should be same and add upto 1.\n",
    "\n",
    "for i in range(n):\n",
    "  #Fit the decision tree(dt_temp) on your data\n",
    "  #Predict on the training set and test set\n",
    "  #Calculate the mean absolute error for each prediction.\n",
    "  #Divide the error by the maximum error (very similar to normalization)\n",
    "  #Calculate the total (weighted) error by summing  errors*sample_weights. This variable is called totalerror\n",
    "  #Calculate a variable called beta = totalerror/(1 - totalerror)\n",
    "  #Calculate alpha as (ln(1/beta)*learning_rate)/2. Learning rate helps us control how much to update the sample weights by.\n",
    "  #Update the sample weight as weight_n+1 = weight_n*(beta^((1 - error)*learning_rate))\n",
    "  #Store the decision trees and values of alpha.(If you perform 14 then 13 is not actually necessary)\n",
    "  #Add the predictions of this decision tree to the ensembled prediction after scaling it with alpha."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3klcP02kRYgHgF/u1syP6",
   "collapsed_sections": [],
   "name": "unit12_Begin.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
